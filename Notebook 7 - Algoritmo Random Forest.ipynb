{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 7: Algoritmo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook está basado en el <a href=\"https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/\"> tutorial</a> propuesto por <a href=\"https://twitter.com/usman_malikk\"> Usman Malik</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Random forest</b> es un tipo de algoritmo de aprendizaje supervisado de máquinas basado en el aprendizaje de conjuntos (Ensemble Learning). <b>Ensemble Learning</b> es un tipo de aprendizaje en el que se unen diferentes tipos de algoritmos o el mismo algoritmo varias veces para formar un modelo de predicción más potente. El algoritmo Random Forest combina múltiples árboles de decisión, dando como resultado un bosque de árboles, de ahí el nombre \"Random Forest\". Random Forest puede utilizarse tanto para tareas de <b>regresión</b> como de <b>clasificación</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ¿Cómo funciona el algoritmo Random Forest?\n",
    "\n",
    "Random Forest se divide en 3 pasos básicos:\n",
    "\n",
    "- Seleccione N registros aleatorios del conjunto de datos.\n",
    "- Construya un árbol de decisión basado en estos registros N. (ver <i>Notebook 6</i>)\n",
    "- Elija el número de árboles que desee en su algoritmo y repita los pasos 1 y 2.\n",
    "\n",
    "En caso de un <b>problema de regresión</b>, para una nueva observación, cada árbol en el bosque predice un valor para Y (salida). El valor final puede ser calculado tomando el promedio de todos los valores pronosticados por todos los árboles en el bosque. \n",
    "\n",
    "En caso de un <b>problema de clasificación</b>, cada árbol del bosque predice la categoría a la que pertenece la nueva observación. Finalmente, la nueva observación se asigna a la categoría que gana la mayoría de los votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ventaja y Desventaja de usar Random Forest\n",
    "\n",
    "Los bosques aleatorios son un método poderoso con varias ventajas:\n",
    "\n",
    "- Tanto el entrenamiento como la predicción son muy rápidos, debido a la simplicidad de los árboles de decisión subyacentes. Además, ambas tareas pueden ser directamente paralelizadas, ya que los árboles individuales son entidades totalmente independientes.\n",
    "- Los múltiples árboles permiten una clasificación probabilística: un voto mayoritario entre los estimadores da una estimación de la probabilidad (accedido en Scikit-Learn con el método predict_proba()).\n",
    "\n",
    "Una desventaja principal de los bosques aleatorios es que los resultados no son fácilmente interpretables: es decir, si se desea sacar conclusiones sobre el significado del modelo de clasificación, los bosques aleatorios pueden no ser la mejor opción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ejemplo de Uso de Random Forest para la regresión\n",
    "\n",
    "En esta sección estudiaremos cómo los bosques aleatorios pueden ser utilizados para resolver problemas de regresión usando Scikit-Learn. En la siguiente sección resolveremos el problema de la clasificación a través de bosques aleatorios.\n",
    "\n",
    "#### Definición del problema\n",
    "\n",
    "El problema aquí es predecir el consumo de gasolina (en millones de galones) en 48 de los estados de los EE.UU. basado en el impuesto a la gasolina (en centavos), el ingreso per cápita (dólares), las carreteras pavimentadas (en millas) y la proporción de la población con la licencia de conducir.\n",
    "\n",
    "#### Solución\n",
    "\n",
    "Para resolver este problema de regresión usaremos el algoritmo de bosque aleatorio a través de la biblioteca Scikit-Learn Python. Seguiremos el proceso de aprendizaje tradicional de la máquina para resolver este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a - Importar y Preparar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.0            3571            1976                         0.525   \n",
       "1         9.0            4092            1250                         0.572   \n",
       "2         9.0            3865            1586                         0.580   \n",
       "3         7.5            4870            2351                         0.529   \n",
       "4         8.0            4399             431                         0.544   \n",
       "\n",
       "   Petrol_Consumption  \n",
       "0                 541  \n",
       "1                 524  \n",
       "2                 561  \n",
       "3                 414  \n",
       "4                 410  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARGAR EL DATASET\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "\n",
    "dataset = pd.read_csv('petrol_consumption.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera tarea es dividir los datos en conjuntos de'atributos' y'etiquetas'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir Features y Labels\n",
    "X = dataset.iloc[:, 0:4].values  \n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, dividamos los datos en conjuntos de entrenamiento y pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b - Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "           oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=1)  \n",
    "regressor.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase <code>RandomForestRegressor</code> de la biblioteca <code>sklearn.ensemble</code> se utiliza para resolver problemas de regresión. El parámetro más importante de la clase <code>RandomForestRegressor</code> es el parámetro <code>n_estimators</code>. Este parámetro define el número de árboles en el bosque aleatorio. Comenzaremos con <code>n_estimator=20</code> para ver cómo funciona nuestro algoritmo. Puede encontrar detalles de todos los parámetros de RandomForestRegressor <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">aquí</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c - Evaluación del modelo Random Forest\n",
    "\n",
    "Para los problemas de regresión, las métricas frecuentemente utilizadas para evaluar un modelo son el error absoluto medio, el error al cuadrado medio y el error al cuadrado medio de la raíz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 47.864999999999995\n",
      "Mean Squared Error: 3422.699249999999\n",
      "Root Mean Squared Error: 58.50383961758407\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Consultas</b>:\n",
    "- ¿Cuál valor de <code>n_estimator</code> permite optimizar el RMSE?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimado: 24\n",
      "RMSE: 56.29958000139373\n"
     ]
    }
   ],
   "source": [
    "estimator = []\n",
    "RMSE = []\n",
    "\n",
    "for i in range(10,101):\n",
    "    regressor = RandomForestRegressor(n_estimators=i, random_state=1)  \n",
    "    regressor.fit(X_train, y_train) \n",
    "    y_pred = regressor.predict(X_test)\n",
    "    RMSE.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    estimator.append(i)\n",
    "\n",
    "X = RMSE.index(min(float(s) for s in RMSE))\n",
    "print(\"n_estimado:\",estimator[X])\n",
    "print(\"RMSE:\", RMSE[X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crear un grafíco que permita visualizar el RMSE obtenido según el <code>n_estimator</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(estimator, RMSE) \n",
    "plt.scatter(estimator, RMSE)\n",
    "plt.xlabel('n_estimador')  \n",
    "plt.ylabel('RMSE')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ejemplo de Uso de Random Forest para la Clasificación\n",
    "\n",
    "#### Definición del problema\n",
    "\n",
    "La tarea aquí es predecir si un billete de banco es auténtico o no basándose en cuatro atributos: la variación de la imagen transformada en ondas, la asimetría, la entropía y la curtosis de la imagen.\n",
    "\n",
    "#### Solución\n",
    "\n",
    "Este es un problema de clasificación binaria y usaremos un clasificador Random Forest para resolver este problema. Los pasos que se sigan para resolver este problema serán similares a los pasos que se realicen para la regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a - Importar y Preparar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy  Class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARGAR EL DATASET\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "\n",
    "dataset = pd.read_csv('bill_authentication.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información detallada sobre los datos está disponible en el siguiente enlace:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/banknote+authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir Features y Labels\n",
    "X = dataset.iloc[:, 0:4].values  \n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>b - Entrenamiento</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)  \n",
    "classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de regresión utilizamos la clase <code>RandomForestRegressor</code> de la biblioteca sklearn.ensemble. Para la clasificación, usaremos la clase <code>RandomForestClassifier</code> de la biblioteca sklearn.ensemble. La clase <code>RandomForestClassifier</code> también toma <code>n_estimadores</code> como parámetro. Como antes, este parámetro define el número de árboles en nuestro bosque aleatorio. Empezaremos con 20 árboles de nuevo. Puede encontrar detalles de todos los parámetros del RandomForestClassifier <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">aquí</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> c - Evaluación del modelo </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los problemas de clasificación, las métricas utilizadas para evaluar un algoritmo son la exactitud, la matriz de confusión, los puntajes de precisión y recall y los valores F1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155   2]\n",
      " [  1 117]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       157\n",
      "          1       0.98      0.99      0.99       118\n",
      "\n",
      "avg / total       0.99      0.99      0.99       275\n",
      "\n",
      "0.9890909090909091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TP: Random Forest\n",
    "\n",
    "1) Encontrar un dataset que les interesa (ver por ejemplo <a href=\"https://www.kaggle.com/datasets\"> Kaggle</a> o <a href=\"https://github.com/awesomedata/awesome-public-datasets\">Awesome public datasets</a>...)\n",
    "\n",
    "2) Describir un problema de clasificación asociado a este dataset, que se podría resolver con un enfoque de aprendizaje supervisado.\n",
    "\n",
    "3) Entrenar y evaluar un modelo Random Forest y compararlo con Decision Tree y Naive Bayes.\n",
    "\n",
    "4) Describir los resultados obtenidos\n",
    "\n",
    "5) ¿Cuáles son los limitpreguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encontro un dataset en Kaggle, llamado avocado.\n",
    "Este dataset tiene información sobre la clasificación de paltas Hass. Los atributos que tiene son:\n",
    "· Fecha\n",
    "· Promedio precio\n",
    "· Volumen total\n",
    "· 4046\n",
    "· 4225\n",
    "· 4770\n",
    "· Total bolsas\n",
    "· Bolsas pequeñas\n",
    "· Bolsas Largas\n",
    "· Bolsas muy largas\n",
    "· Tipo\n",
    "· Año\n",
    "· Región"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0  2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1  2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2  2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3  2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4  2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('avocado.csv', index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-11-22</td>\n",
       "      <td>1.26</td>\n",
       "      <td>55979.78</td>\n",
       "      <td>1184.27</td>\n",
       "      <td>48067.99</td>\n",
       "      <td>43.61</td>\n",
       "      <td>6683.91</td>\n",
       "      <td>6556.47</td>\n",
       "      <td>127.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>0.99</td>\n",
       "      <td>83453.76</td>\n",
       "      <td>1368.92</td>\n",
       "      <td>73672.72</td>\n",
       "      <td>93.26</td>\n",
       "      <td>8318.86</td>\n",
       "      <td>8196.81</td>\n",
       "      <td>122.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-11-08</td>\n",
       "      <td>0.98</td>\n",
       "      <td>109428.33</td>\n",
       "      <td>703.75</td>\n",
       "      <td>101815.36</td>\n",
       "      <td>80.00</td>\n",
       "      <td>6829.22</td>\n",
       "      <td>6266.85</td>\n",
       "      <td>562.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>1.02</td>\n",
       "      <td>99811.42</td>\n",
       "      <td>1022.15</td>\n",
       "      <td>87315.57</td>\n",
       "      <td>85.34</td>\n",
       "      <td>11388.36</td>\n",
       "      <td>11104.53</td>\n",
       "      <td>283.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>1.07</td>\n",
       "      <td>74338.76</td>\n",
       "      <td>842.40</td>\n",
       "      <td>64757.44</td>\n",
       "      <td>113.00</td>\n",
       "      <td>8625.92</td>\n",
       "      <td>8061.47</td>\n",
       "      <td>564.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>1.12</td>\n",
       "      <td>84843.44</td>\n",
       "      <td>924.86</td>\n",
       "      <td>75595.85</td>\n",
       "      <td>117.07</td>\n",
       "      <td>8205.66</td>\n",
       "      <td>7877.86</td>\n",
       "      <td>327.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-10-11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>64489.17</td>\n",
       "      <td>1582.03</td>\n",
       "      <td>52677.92</td>\n",
       "      <td>105.32</td>\n",
       "      <td>10123.90</td>\n",
       "      <td>9866.27</td>\n",
       "      <td>257.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-10-04</td>\n",
       "      <td>1.31</td>\n",
       "      <td>61007.10</td>\n",
       "      <td>2268.32</td>\n",
       "      <td>49880.67</td>\n",
       "      <td>101.36</td>\n",
       "      <td>8756.75</td>\n",
       "      <td>8379.98</td>\n",
       "      <td>376.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>0.99</td>\n",
       "      <td>106803.39</td>\n",
       "      <td>1204.88</td>\n",
       "      <td>99409.21</td>\n",
       "      <td>154.84</td>\n",
       "      <td>6034.46</td>\n",
       "      <td>5888.87</td>\n",
       "      <td>145.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-09-20</td>\n",
       "      <td>1.33</td>\n",
       "      <td>69759.01</td>\n",
       "      <td>1028.03</td>\n",
       "      <td>59313.12</td>\n",
       "      <td>150.50</td>\n",
       "      <td>9267.36</td>\n",
       "      <td>8489.10</td>\n",
       "      <td>778.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>1.28</td>\n",
       "      <td>76111.27</td>\n",
       "      <td>985.73</td>\n",
       "      <td>65696.86</td>\n",
       "      <td>142.00</td>\n",
       "      <td>9286.68</td>\n",
       "      <td>8665.19</td>\n",
       "      <td>621.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-09-06</td>\n",
       "      <td>1.11</td>\n",
       "      <td>99172.96</td>\n",
       "      <td>879.45</td>\n",
       "      <td>90062.62</td>\n",
       "      <td>240.79</td>\n",
       "      <td>7990.10</td>\n",
       "      <td>7762.87</td>\n",
       "      <td>227.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-08-30</td>\n",
       "      <td>1.07</td>\n",
       "      <td>105693.84</td>\n",
       "      <td>689.01</td>\n",
       "      <td>94362.67</td>\n",
       "      <td>335.43</td>\n",
       "      <td>10306.73</td>\n",
       "      <td>10218.93</td>\n",
       "      <td>87.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-08-23</td>\n",
       "      <td>1.34</td>\n",
       "      <td>79992.09</td>\n",
       "      <td>733.16</td>\n",
       "      <td>67933.79</td>\n",
       "      <td>444.78</td>\n",
       "      <td>10880.36</td>\n",
       "      <td>10745.79</td>\n",
       "      <td>134.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-08-16</td>\n",
       "      <td>1.33</td>\n",
       "      <td>80043.78</td>\n",
       "      <td>539.65</td>\n",
       "      <td>68666.01</td>\n",
       "      <td>394.90</td>\n",
       "      <td>10443.22</td>\n",
       "      <td>10297.68</td>\n",
       "      <td>145.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>1.12</td>\n",
       "      <td>111140.93</td>\n",
       "      <td>584.63</td>\n",
       "      <td>100961.46</td>\n",
       "      <td>368.95</td>\n",
       "      <td>9225.89</td>\n",
       "      <td>9116.34</td>\n",
       "      <td>109.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-08-02</td>\n",
       "      <td>1.45</td>\n",
       "      <td>75133.10</td>\n",
       "      <td>509.94</td>\n",
       "      <td>62035.06</td>\n",
       "      <td>741.08</td>\n",
       "      <td>11847.02</td>\n",
       "      <td>11768.52</td>\n",
       "      <td>78.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>1.11</td>\n",
       "      <td>106757.10</td>\n",
       "      <td>648.75</td>\n",
       "      <td>91949.05</td>\n",
       "      <td>966.61</td>\n",
       "      <td>13192.69</td>\n",
       "      <td>13061.53</td>\n",
       "      <td>131.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>1.26</td>\n",
       "      <td>96617.00</td>\n",
       "      <td>1042.10</td>\n",
       "      <td>82049.40</td>\n",
       "      <td>2238.02</td>\n",
       "      <td>11287.48</td>\n",
       "      <td>11103.49</td>\n",
       "      <td>183.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-07-12</td>\n",
       "      <td>1.05</td>\n",
       "      <td>124055.31</td>\n",
       "      <td>672.25</td>\n",
       "      <td>94693.52</td>\n",
       "      <td>4257.64</td>\n",
       "      <td>24431.90</td>\n",
       "      <td>24290.08</td>\n",
       "      <td>108.49</td>\n",
       "      <td>33.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>1.35</td>\n",
       "      <td>109252.12</td>\n",
       "      <td>869.45</td>\n",
       "      <td>72600.55</td>\n",
       "      <td>5883.16</td>\n",
       "      <td>29898.96</td>\n",
       "      <td>29663.19</td>\n",
       "      <td>235.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>1.37</td>\n",
       "      <td>89534.81</td>\n",
       "      <td>664.23</td>\n",
       "      <td>57545.79</td>\n",
       "      <td>4662.71</td>\n",
       "      <td>26662.08</td>\n",
       "      <td>26311.76</td>\n",
       "      <td>350.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2015-06-21</td>\n",
       "      <td>1.27</td>\n",
       "      <td>104849.39</td>\n",
       "      <td>804.01</td>\n",
       "      <td>76688.55</td>\n",
       "      <td>5481.18</td>\n",
       "      <td>21875.65</td>\n",
       "      <td>21662.00</td>\n",
       "      <td>213.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2015-06-14</td>\n",
       "      <td>1.32</td>\n",
       "      <td>89631.30</td>\n",
       "      <td>850.58</td>\n",
       "      <td>55400.94</td>\n",
       "      <td>4377.19</td>\n",
       "      <td>29002.59</td>\n",
       "      <td>28343.14</td>\n",
       "      <td>659.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015-06-07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>122743.06</td>\n",
       "      <td>656.71</td>\n",
       "      <td>99220.82</td>\n",
       "      <td>90.32</td>\n",
       "      <td>22775.21</td>\n",
       "      <td>22314.99</td>\n",
       "      <td>460.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1317000.47</td>\n",
       "      <td>98465.26</td>\n",
       "      <td>270798.27</td>\n",
       "      <td>1839.80</td>\n",
       "      <td>945638.02</td>\n",
       "      <td>768242.42</td>\n",
       "      <td>177144.00</td>\n",
       "      <td>251.60</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>TotalUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1384683.41</td>\n",
       "      <td>117922.52</td>\n",
       "      <td>287724.61</td>\n",
       "      <td>1703.52</td>\n",
       "      <td>977084.84</td>\n",
       "      <td>774695.74</td>\n",
       "      <td>201878.69</td>\n",
       "      <td>510.41</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>TotalUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1336979.09</td>\n",
       "      <td>118616.17</td>\n",
       "      <td>280080.34</td>\n",
       "      <td>1270.61</td>\n",
       "      <td>936859.49</td>\n",
       "      <td>796104.27</td>\n",
       "      <td>140652.84</td>\n",
       "      <td>102.38</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>TotalUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1283987.65</td>\n",
       "      <td>108705.28</td>\n",
       "      <td>259172.13</td>\n",
       "      <td>1490.02</td>\n",
       "      <td>914409.26</td>\n",
       "      <td>710654.40</td>\n",
       "      <td>203526.59</td>\n",
       "      <td>228.27</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>TotalUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1476651.08</td>\n",
       "      <td>145680.62</td>\n",
       "      <td>323669.83</td>\n",
       "      <td>1580.01</td>\n",
       "      <td>1005593.78</td>\n",
       "      <td>858772.69</td>\n",
       "      <td>146808.97</td>\n",
       "      <td>12.12</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>TotalUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1517332.70</td>\n",
       "      <td>129541.43</td>\n",
       "      <td>296490.29</td>\n",
       "      <td>1289.07</td>\n",
       "      <td>1089861.24</td>\n",
       "      <td>915452.78</td>\n",
       "      <td>174381.57</td>\n",
       "      <td>26.89</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>TotalUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.60</td>\n",
       "      <td>271723.08</td>\n",
       "      <td>26996.28</td>\n",
       "      <td>77861.39</td>\n",
       "      <td>117.56</td>\n",
       "      <td>166747.85</td>\n",
       "      <td>87108.00</td>\n",
       "      <td>79495.39</td>\n",
       "      <td>144.46</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.73</td>\n",
       "      <td>210067.47</td>\n",
       "      <td>33437.98</td>\n",
       "      <td>47165.54</td>\n",
       "      <td>110.40</td>\n",
       "      <td>129353.55</td>\n",
       "      <td>73163.12</td>\n",
       "      <td>56020.24</td>\n",
       "      <td>170.19</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>1.63</td>\n",
       "      <td>264691.87</td>\n",
       "      <td>27566.25</td>\n",
       "      <td>60383.57</td>\n",
       "      <td>276.42</td>\n",
       "      <td>176465.63</td>\n",
       "      <td>107174.93</td>\n",
       "      <td>69290.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>1.46</td>\n",
       "      <td>347373.17</td>\n",
       "      <td>25990.60</td>\n",
       "      <td>71213.19</td>\n",
       "      <td>79.01</td>\n",
       "      <td>250090.37</td>\n",
       "      <td>85835.17</td>\n",
       "      <td>164087.33</td>\n",
       "      <td>167.87</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>1.49</td>\n",
       "      <td>301985.61</td>\n",
       "      <td>34200.18</td>\n",
       "      <td>49139.34</td>\n",
       "      <td>85.58</td>\n",
       "      <td>218560.51</td>\n",
       "      <td>99989.62</td>\n",
       "      <td>118314.77</td>\n",
       "      <td>256.12</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>1.64</td>\n",
       "      <td>224798.60</td>\n",
       "      <td>30149.00</td>\n",
       "      <td>38800.64</td>\n",
       "      <td>123.13</td>\n",
       "      <td>155725.83</td>\n",
       "      <td>120428.13</td>\n",
       "      <td>35257.73</td>\n",
       "      <td>39.97</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>1.47</td>\n",
       "      <td>275248.53</td>\n",
       "      <td>24732.55</td>\n",
       "      <td>61713.53</td>\n",
       "      <td>243.00</td>\n",
       "      <td>188559.45</td>\n",
       "      <td>88497.05</td>\n",
       "      <td>99810.80</td>\n",
       "      <td>251.60</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>1.41</td>\n",
       "      <td>283378.47</td>\n",
       "      <td>22474.66</td>\n",
       "      <td>55360.49</td>\n",
       "      <td>133.41</td>\n",
       "      <td>205409.91</td>\n",
       "      <td>70232.59</td>\n",
       "      <td>134666.91</td>\n",
       "      <td>510.41</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>1.80</td>\n",
       "      <td>185974.53</td>\n",
       "      <td>22918.40</td>\n",
       "      <td>33051.14</td>\n",
       "      <td>93.52</td>\n",
       "      <td>129911.47</td>\n",
       "      <td>77822.23</td>\n",
       "      <td>51986.86</td>\n",
       "      <td>102.38</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>1.83</td>\n",
       "      <td>189317.99</td>\n",
       "      <td>27049.44</td>\n",
       "      <td>33561.32</td>\n",
       "      <td>439.47</td>\n",
       "      <td>128267.76</td>\n",
       "      <td>76091.99</td>\n",
       "      <td>51947.50</td>\n",
       "      <td>228.27</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>1.82</td>\n",
       "      <td>207999.67</td>\n",
       "      <td>33869.12</td>\n",
       "      <td>47435.14</td>\n",
       "      <td>433.52</td>\n",
       "      <td>126261.89</td>\n",
       "      <td>89115.78</td>\n",
       "      <td>37133.99</td>\n",
       "      <td>12.12</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>1.48</td>\n",
       "      <td>297190.60</td>\n",
       "      <td>34734.97</td>\n",
       "      <td>62967.74</td>\n",
       "      <td>157.77</td>\n",
       "      <td>199330.12</td>\n",
       "      <td>103761.55</td>\n",
       "      <td>95544.39</td>\n",
       "      <td>24.18</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>1.62</td>\n",
       "      <td>15303.40</td>\n",
       "      <td>2325.30</td>\n",
       "      <td>2171.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10806.44</td>\n",
       "      <td>10569.80</td>\n",
       "      <td>236.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>15896.38</td>\n",
       "      <td>2055.35</td>\n",
       "      <td>1499.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12341.48</td>\n",
       "      <td>12114.81</td>\n",
       "      <td>226.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>1.56</td>\n",
       "      <td>22128.42</td>\n",
       "      <td>2162.67</td>\n",
       "      <td>3194.25</td>\n",
       "      <td>8.93</td>\n",
       "      <td>16762.57</td>\n",
       "      <td>16510.32</td>\n",
       "      <td>252.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-04</td>\n",
       "      <td>1.54</td>\n",
       "      <td>17393.30</td>\n",
       "      <td>1832.24</td>\n",
       "      <td>1905.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13655.49</td>\n",
       "      <td>13401.93</td>\n",
       "      <td>253.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-25</td>\n",
       "      <td>1.57</td>\n",
       "      <td>18421.24</td>\n",
       "      <td>1974.26</td>\n",
       "      <td>2482.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13964.33</td>\n",
       "      <td>13698.27</td>\n",
       "      <td>266.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>1.56</td>\n",
       "      <td>17597.12</td>\n",
       "      <td>1892.05</td>\n",
       "      <td>1928.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13776.71</td>\n",
       "      <td>13553.53</td>\n",
       "      <td>223.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>1.57</td>\n",
       "      <td>15986.17</td>\n",
       "      <td>1924.28</td>\n",
       "      <td>1368.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12693.57</td>\n",
       "      <td>12437.35</td>\n",
       "      <td>256.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-02-04</td>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "      <td>2046.96</td>\n",
       "      <td>1529.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>1.71</td>\n",
       "      <td>13888.04</td>\n",
       "      <td>1191.70</td>\n",
       "      <td>3431.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "      <td>1191.92</td>\n",
       "      <td>2452.79</td>\n",
       "      <td>727.94</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "      <td>1527.63</td>\n",
       "      <td>2981.04</td>\n",
       "      <td>727.01</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-07</td>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "      <td>2894.77</td>\n",
       "      <td>2356.13</td>\n",
       "      <td>224.53</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>WestTexNewMexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18249 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AveragePrice  Total Volume       4046       4225     4770  \\\n",
       "0   2015-12-27          1.33      64236.62    1036.74   54454.85    48.16   \n",
       "1   2015-12-20          1.35      54876.98     674.28   44638.81    58.33   \n",
       "2   2015-12-13          0.93     118220.22     794.70  109149.67   130.50   \n",
       "3   2015-12-06          1.08      78992.15    1132.00   71976.41    72.58   \n",
       "4   2015-11-29          1.28      51039.60     941.48   43838.39    75.78   \n",
       "5   2015-11-22          1.26      55979.78    1184.27   48067.99    43.61   \n",
       "6   2015-11-15          0.99      83453.76    1368.92   73672.72    93.26   \n",
       "7   2015-11-08          0.98     109428.33     703.75  101815.36    80.00   \n",
       "8   2015-11-01          1.02      99811.42    1022.15   87315.57    85.34   \n",
       "9   2015-10-25          1.07      74338.76     842.40   64757.44   113.00   \n",
       "10  2015-10-18          1.12      84843.44     924.86   75595.85   117.07   \n",
       "11  2015-10-11          1.28      64489.17    1582.03   52677.92   105.32   \n",
       "12  2015-10-04          1.31      61007.10    2268.32   49880.67   101.36   \n",
       "13  2015-09-27          0.99     106803.39    1204.88   99409.21   154.84   \n",
       "14  2015-09-20          1.33      69759.01    1028.03   59313.12   150.50   \n",
       "15  2015-09-13          1.28      76111.27     985.73   65696.86   142.00   \n",
       "16  2015-09-06          1.11      99172.96     879.45   90062.62   240.79   \n",
       "17  2015-08-30          1.07     105693.84     689.01   94362.67   335.43   \n",
       "18  2015-08-23          1.34      79992.09     733.16   67933.79   444.78   \n",
       "19  2015-08-16          1.33      80043.78     539.65   68666.01   394.90   \n",
       "20  2015-08-09          1.12     111140.93     584.63  100961.46   368.95   \n",
       "21  2015-08-02          1.45      75133.10     509.94   62035.06   741.08   \n",
       "22  2015-07-26          1.11     106757.10     648.75   91949.05   966.61   \n",
       "23  2015-07-19          1.26      96617.00    1042.10   82049.40  2238.02   \n",
       "24  2015-07-12          1.05     124055.31     672.25   94693.52  4257.64   \n",
       "25  2015-07-05          1.35     109252.12     869.45   72600.55  5883.16   \n",
       "26  2015-06-28          1.37      89534.81     664.23   57545.79  4662.71   \n",
       "27  2015-06-21          1.27     104849.39     804.01   76688.55  5481.18   \n",
       "28  2015-06-14          1.32      89631.30     850.58   55400.94  4377.19   \n",
       "29  2015-06-07          1.07     122743.06     656.71   99220.82    90.32   \n",
       "..         ...           ...           ...        ...        ...      ...   \n",
       "6   2018-02-11          1.56    1317000.47   98465.26  270798.27  1839.80   \n",
       "7   2018-02-04          1.53    1384683.41  117922.52  287724.61  1703.52   \n",
       "8   2018-01-28          1.61    1336979.09  118616.17  280080.34  1270.61   \n",
       "9   2018-01-21          1.63    1283987.65  108705.28  259172.13  1490.02   \n",
       "10  2018-01-14          1.59    1476651.08  145680.62  323669.83  1580.01   \n",
       "11  2018-01-07          1.51    1517332.70  129541.43  296490.29  1289.07   \n",
       "0   2018-03-25          1.60     271723.08   26996.28   77861.39   117.56   \n",
       "1   2018-03-18          1.73     210067.47   33437.98   47165.54   110.40   \n",
       "2   2018-03-11          1.63     264691.87   27566.25   60383.57   276.42   \n",
       "3   2018-03-04          1.46     347373.17   25990.60   71213.19    79.01   \n",
       "4   2018-02-25          1.49     301985.61   34200.18   49139.34    85.58   \n",
       "5   2018-02-18          1.64     224798.60   30149.00   38800.64   123.13   \n",
       "6   2018-02-11          1.47     275248.53   24732.55   61713.53   243.00   \n",
       "7   2018-02-04          1.41     283378.47   22474.66   55360.49   133.41   \n",
       "8   2018-01-28          1.80     185974.53   22918.40   33051.14    93.52   \n",
       "9   2018-01-21          1.83     189317.99   27049.44   33561.32   439.47   \n",
       "10  2018-01-14          1.82     207999.67   33869.12   47435.14   433.52   \n",
       "11  2018-01-07          1.48     297190.60   34734.97   62967.74   157.77   \n",
       "0   2018-03-25          1.62      15303.40    2325.30    2171.66     0.00   \n",
       "1   2018-03-18          1.56      15896.38    2055.35    1499.55     0.00   \n",
       "2   2018-03-11          1.56      22128.42    2162.67    3194.25     8.93   \n",
       "3   2018-03-04          1.54      17393.30    1832.24    1905.57     0.00   \n",
       "4   2018-02-25          1.57      18421.24    1974.26    2482.65     0.00   \n",
       "5   2018-02-18          1.56      17597.12    1892.05    1928.36     0.00   \n",
       "6   2018-02-11          1.57      15986.17    1924.28    1368.32     0.00   \n",
       "7   2018-02-04          1.63      17074.83    2046.96    1529.20     0.00   \n",
       "8   2018-01-28          1.71      13888.04    1191.70    3431.50     0.00   \n",
       "9   2018-01-21          1.87      13766.76    1191.92    2452.79   727.94   \n",
       "10  2018-01-14          1.93      16205.22    1527.63    2981.04   727.01   \n",
       "11  2018-01-07          1.62      17489.58    2894.77    2356.13   224.53   \n",
       "\n",
       "    Total Bags  Small Bags  Large Bags  XLarge Bags  type  year  \\\n",
       "0      8696.87     8603.62       93.25         0.00     1  2015   \n",
       "1      9505.56     9408.07       97.49         0.00     1  2015   \n",
       "2      8145.35     8042.21      103.14         0.00     1  2015   \n",
       "3      5811.16     5677.40      133.76         0.00     1  2015   \n",
       "4      6183.95     5986.26      197.69         0.00     1  2015   \n",
       "5      6683.91     6556.47      127.44         0.00     1  2015   \n",
       "6      8318.86     8196.81      122.05         0.00     1  2015   \n",
       "7      6829.22     6266.85      562.37         0.00     1  2015   \n",
       "8     11388.36    11104.53      283.83         0.00     1  2015   \n",
       "9      8625.92     8061.47      564.45         0.00     1  2015   \n",
       "10     8205.66     7877.86      327.80         0.00     1  2015   \n",
       "11    10123.90     9866.27      257.63         0.00     1  2015   \n",
       "12     8756.75     8379.98      376.77         0.00     1  2015   \n",
       "13     6034.46     5888.87      145.59         0.00     1  2015   \n",
       "14     9267.36     8489.10      778.26         0.00     1  2015   \n",
       "15     9286.68     8665.19      621.49         0.00     1  2015   \n",
       "16     7990.10     7762.87      227.23         0.00     1  2015   \n",
       "17    10306.73    10218.93       87.80         0.00     1  2015   \n",
       "18    10880.36    10745.79      134.57         0.00     1  2015   \n",
       "19    10443.22    10297.68      145.54         0.00     1  2015   \n",
       "20     9225.89     9116.34      109.55         0.00     1  2015   \n",
       "21    11847.02    11768.52       78.50         0.00     1  2015   \n",
       "22    13192.69    13061.53      131.16         0.00     1  2015   \n",
       "23    11287.48    11103.49      183.99         0.00     1  2015   \n",
       "24    24431.90    24290.08      108.49        33.33     1  2015   \n",
       "25    29898.96    29663.19      235.77         0.00     1  2015   \n",
       "26    26662.08    26311.76      350.32         0.00     1  2015   \n",
       "27    21875.65    21662.00      213.65         0.00     1  2015   \n",
       "28    29002.59    28343.14      659.45         0.00     1  2015   \n",
       "29    22775.21    22314.99      460.22         0.00     1  2015   \n",
       "..         ...         ...         ...          ...   ...   ...   \n",
       "6    945638.02   768242.42   177144.00       251.60     0  2018   \n",
       "7    977084.84   774695.74   201878.69       510.41     0  2018   \n",
       "8    936859.49   796104.27   140652.84       102.38     0  2018   \n",
       "9    914409.26   710654.40   203526.59       228.27     0  2018   \n",
       "10  1005593.78   858772.69   146808.97        12.12     0  2018   \n",
       "11  1089861.24   915452.78   174381.57        26.89     0  2018   \n",
       "0    166747.85    87108.00    79495.39       144.46     0  2018   \n",
       "1    129353.55    73163.12    56020.24       170.19     0  2018   \n",
       "2    176465.63   107174.93    69290.70         0.00     0  2018   \n",
       "3    250090.37    85835.17   164087.33       167.87     0  2018   \n",
       "4    218560.51    99989.62   118314.77       256.12     0  2018   \n",
       "5    155725.83   120428.13    35257.73        39.97     0  2018   \n",
       "6    188559.45    88497.05    99810.80       251.60     0  2018   \n",
       "7    205409.91    70232.59   134666.91       510.41     0  2018   \n",
       "8    129911.47    77822.23    51986.86       102.38     0  2018   \n",
       "9    128267.76    76091.99    51947.50       228.27     0  2018   \n",
       "10   126261.89    89115.78    37133.99        12.12     0  2018   \n",
       "11   199330.12   103761.55    95544.39        24.18     0  2018   \n",
       "0     10806.44    10569.80      236.64         0.00     0  2018   \n",
       "1     12341.48    12114.81      226.67         0.00     0  2018   \n",
       "2     16762.57    16510.32      252.25         0.00     0  2018   \n",
       "3     13655.49    13401.93      253.56         0.00     0  2018   \n",
       "4     13964.33    13698.27      266.06         0.00     0  2018   \n",
       "5     13776.71    13553.53      223.18         0.00     0  2018   \n",
       "6     12693.57    12437.35      256.22         0.00     0  2018   \n",
       "7     13498.67    13066.82      431.85         0.00     0  2018   \n",
       "8      9264.84     8940.04      324.80         0.00     0  2018   \n",
       "9      9394.11     9351.80       42.31         0.00     0  2018   \n",
       "10    10969.54    10919.54       50.00         0.00     0  2018   \n",
       "11    12014.15    11988.14       26.01         0.00     0  2018   \n",
       "\n",
       "              region  \n",
       "0             Albany  \n",
       "1             Albany  \n",
       "2             Albany  \n",
       "3             Albany  \n",
       "4             Albany  \n",
       "5             Albany  \n",
       "6             Albany  \n",
       "7             Albany  \n",
       "8             Albany  \n",
       "9             Albany  \n",
       "10            Albany  \n",
       "11            Albany  \n",
       "12            Albany  \n",
       "13            Albany  \n",
       "14            Albany  \n",
       "15            Albany  \n",
       "16            Albany  \n",
       "17            Albany  \n",
       "18            Albany  \n",
       "19            Albany  \n",
       "20            Albany  \n",
       "21            Albany  \n",
       "22            Albany  \n",
       "23            Albany  \n",
       "24            Albany  \n",
       "25            Albany  \n",
       "26            Albany  \n",
       "27            Albany  \n",
       "28            Albany  \n",
       "29            Albany  \n",
       "..               ...  \n",
       "6            TotalUS  \n",
       "7            TotalUS  \n",
       "8            TotalUS  \n",
       "9            TotalUS  \n",
       "10           TotalUS  \n",
       "11           TotalUS  \n",
       "0               West  \n",
       "1               West  \n",
       "2               West  \n",
       "3               West  \n",
       "4               West  \n",
       "5               West  \n",
       "6               West  \n",
       "7               West  \n",
       "8               West  \n",
       "9               West  \n",
       "10              West  \n",
       "11              West  \n",
       "0   WestTexNewMexico  \n",
       "1   WestTexNewMexico  \n",
       "2   WestTexNewMexico  \n",
       "3   WestTexNewMexico  \n",
       "4   WestTexNewMexico  \n",
       "5   WestTexNewMexico  \n",
       "6   WestTexNewMexico  \n",
       "7   WestTexNewMexico  \n",
       "8   WestTexNewMexico  \n",
       "9   WestTexNewMexico  \n",
       "10  WestTexNewMexico  \n",
       "11  WestTexNewMexico  \n",
       "\n",
       "[18249 rows x 13 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['type'] = dataset['type'].str.contains(\"conventional\")*1\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols=list(dataset)\n",
    "feature_cols.remove('type')\n",
    "feature_cols.remove('region')\n",
    "feature_cols.remove('Date')\n",
    "X = dataset[feature_cols]\n",
    "y = dataset['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "[[1858   17]\n",
      " [  11 1764]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      1875\n",
      "          1       0.99      0.99      0.99      1775\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3650\n",
      "\n",
      "0.9923287671232877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)  \n",
    "classifier.fit(X_train, y_train)    \n",
    "\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(\"Random Forest:\")\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree:\n",
      "[[1858   17]\n",
      " [  11 1764]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      1875\n",
      "          1       0.99      0.99      0.99      1775\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3650\n",
      "\n",
      "0.9923287671232877\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  \n",
    "decitionTC = tree.DecisionTreeClassifier()\n",
    "decitionTC=decitionTC.fit(X_train,y_train)\n",
    "decitionTC\n",
    "decitionT_y_predicted=decitionTC.predict(X_test)\n",
    "print(\"Decision Tree:\")\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:\n",
      "[[1838   37]\n",
      " [ 493 1282]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.98      0.87      1875\n",
      "          1       0.97      0.72      0.83      1775\n",
      "\n",
      "avg / total       0.88      0.85      0.85      3650\n",
      "\n",
      "0.8547945205479452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  \n",
    "gaussianb = GaussianNB()\n",
    "y_pred = gaussianb.fit(X_train,y_train).predict(X_test)\n",
    "print(\"Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
